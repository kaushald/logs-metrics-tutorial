version: "3.7"

services:
  # The 'setup' service runs a one-off script which initializes the
  # 'logstash_internal' and 'kibana_system' users inside Elasticsearch with the
  # values of the passwords defined in the '.env' file.
  #
  # This task is only performed during the *initial* startup of the stack. On all
  # subsequent runs, the service simply returns immediately, without performing
  # any modification to existing users.
  setup:
    build:
      context: setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - setup:/state:Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,z
      - elasticsearch:/usr/share/elasticsearch/data:z
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
      - ./logs:/logs
    ports:
      - "5044:5044"
      - "50000:50000/tcp"
      - "50000:50000/udp"
      - "9600:9600"
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - "5601:5601"
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      # Fleet plugin
      KIBANA_FLEET_SETUP: "1"
    networks:
      - elk
    depends_on:
      - elasticsearch

  app:
    container_name: leaky_app
    build: .
    ports:
      - "8080:8080"
    networks:
      - elk
    volumes:
      - ./logs:/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://app:8080/actuator/health"]
      interval: 10s
      timeout: 10s
      retries: 10

  influxdb:
    container_name: leaky_influxdb
    image: influxdb:1.8.9
    ports:
      - "8086:8086"
    volumes:
      - influxdb-storage:/var/lib/influxdb
    networks:
      - elk
    environment:
      - INFLUXDB_DB=myk6db
      - INFLUXDB_ADMIN_USER=leakyadmin
      - INFLUXDB_ADMIN_PASSWORD=leakyadmin

  prometheus:
    container_name: leaky_prometheus
    image: prom/prometheus:v2.30.3
    ports:
      - "9090:9090"
    networks:
      - elk
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9090"]
      interval: 10s
      timeout: 10s
      retries: 10
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    container_name: leaky_grafana
    build: "./grafana"
    ports:
      - "3000:3000"
    links:
      - influxdb:influxdb
    networks:
      - elk
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3030"]
      interval: 10s
      timeout: 10s
      retries: 10

networks:
  elk:
    driver: bridge

volumes:
  setup:
  elasticsearch:
  grafana-storage:
  influxdb-storage:
